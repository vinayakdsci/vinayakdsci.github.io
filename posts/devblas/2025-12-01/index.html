<!doctype html><html class="dark light" lang=en><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content=https://vinayakdsci.github.io name=base><title>
            
                Building BLAS, Part 2: Introducing devblas
            
        </title><meta content="Building BLAS, Part 2: Introducing devblas" property=og:title><link href=https://vinayakdsci.github.io/fonts.css rel=stylesheet><script src=https://vinayakdsci.github.io/js/codeblock.js></script><script src=https://vinayakdsci.github.io/js/note.js></script><script>MathJax = {
              tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
              }
            };</script><script async id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link href=https://vinayakdsci.github.io/atom.xml rel=alternate title=vinayakdsci type=application/atom+xml><link href=https://vinayakdsci.github.io/theme/light.css rel=stylesheet><link href=https://vinayakdsci.github.io/theme/dark.css id=darkModeStyle rel=stylesheet><script src=https://vinayakdsci.github.io/js/themetoggle.js></script><script>setTheme(getSavedTheme());</script><link href=https://vinayakdsci.github.io/main.css media=screen rel=stylesheet><script src="https://vinayakdsci.github.io/js/searchElasticlunr.min.js?h=3626c0ef99daa745b31e" defer></script><body><div class=content><header><div class=main><a href=https://vinayakdsci.github.io>vinayakdsci</a><div class=socials><a class=social href=https://linkedin.com/in/vinayakdsci rel=me> <img alt=linkedin src=https://vinayakdsci.github.io/icons/social/linkedin.svg> </a><a class=social href=https://github.com/vinayakdsci/ rel=me> <img alt=github src=https://vinayakdsci.github.io/icons/social/github.svg> </a><a class=social href=/atom.xml rel=me> <img alt=rss src=https://vinayakdsci.github.io/icons/social/rss.svg> </a></div></div><nav><a href=https://vinayakdsci.github.io/about style=margin-left:.25em>About </a><button title="$SHORTCUT to open search" class=search-button id=search-button><img alt=Search class=search-icon src=https://vinayakdsci.github.io/icons/search.svg></button><div class="search-modal js" aria-labelledby=modalTitle id=searchModal role=dialog><div id=modal-content><h1 class=page-header id=modalTitle>Search</h1><div id=searchBar><input aria-controls=results-container aria-expanded=false autocomplete=off id=searchInput placeholder=Search... role=combobox spellcheck=false><button title="Clear search" class=clear-button id=clear-search><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="m256-200-56-56 224-224-224-224 56-56 224 224 224-224 56 56-224 224 224 224-56 56-224-224-224 224Z"/></svg></button></div><div id=results-container><div id=results-info><span id=zero_results style=display:none>No results</span><span id=one_result style=display:none>1 result</span><span id=many_results style=display:none>$NUMBER results</span></div><div id=results role=listbox></div></div></div></div><a onclick="toggleTheme(); event.preventDefault();" href=# id=dark-mode-toggle> <img alt=Light id=sun-icon src=https://vinayakdsci.github.io/icons/sun.svg style=filter:invert()> <img alt=Dark id=moon-icon src=https://vinayakdsci.github.io/icons/moon.svg> </a><script>updateItemToggleTheme()</script></nav></header><main><article><div class=title><div class=page-header>Building BLAS, Part 2: Introducing devblas<span class=primary-color style=font-size:1.6em>.</span></div><div class=meta>Posted on <time>2025-12-01</time> :: 1620 Words</div></div><section class=body><h3 id=why-a-separate-post-to-introduce-the-library>Why a separate post to introduce the library?</h3><p>In the previous post in the BLAS series, we looked at how <code>NumPy</code> significantly outperformed a naive <code>IJK</code> ordered three-loop C++ implementation on the same matrix sizes. The post was an announcement for both the blog series and the library we will implement as the series progresses. Over the past two weeks, I spent some time setting up the library and plugging in our naive C++ implementation into the codebase.<p>However, the efforts resulted in a codebase that has now become large enough to deserve its own introduction post, so that you do not feel lost when I use code from the library to demonstrate the concepts we will discuss in upcoming posts.<p>In its entirety, the library at the moment consists of a naive <code>IJK</code> ordered IGEMM/SGEMM implementation exposed via C, but internally implemented in C++ so that we can use templates to write reusable code. I have deliberately avoided the use of classes and other OOP constructs to avoid runtime overhead, and I expose the API in C to maintain a stable ABI.<p>The library also provides a generic benchmarking harness (which we'll use a lot) that allows the user to pass in a function pointer to their own implementation of a GEMM for benchmarking, as long as it follows the specified function signature.<p>So, to avoid cluttering other posts with implementation details from the library, I decided to write an intro to it. In this post, we'll discuss the implementation and design details, and how to use it to benchmark your own experimental kernels.<p>The library lives <a href=https://github.com/vinayakdsci/devblas>here on Github</a>. The README will have instructions on building, but I will very quickly give a brief overview.<h3 id=building-and-linking>Building and linking</h3><p>Let's say that you've cloned the repository to <code>~/devblas</code> (a simple git clone in the home dir).<p>Here's a quick overview before we move into the internal details. (These instructions are also there on the repository README, I am just repeating here for completeness).<p>To build, we'll first have to generate the build files with CMake and then run the build command. I recommend having a recent enough version of CMake and Ninja installed. To build, run CMake in the top-level of the repository.<pre class=language-sh data-lang=sh style=color:#c0c5ce;background-color:#2b303b><code class=language-sh data-lang=sh><span style=color:#bf616a>$</span><span> cmake</span><span style=color:#bf616a> -S</span><span>.</span><span style=color:#bf616a> -Bbuild -GNinja -DCMAKE_C_COMPILER</span><span>=clang \
</span><span style=color:#bf616a>  -DCMAKE_CXX_COMPILER</span><span>=clang++</span><span style=color:#bf616a> -DCMAKE_BUILD_TYPE</span><span>=Release \
</span><span style=color:#bf616a>  -DCMAKE_INSTALL_PREFIX</span><span>=devblas_libs
</span></code></pre><p>You can plug in your own C and C++ compilers here. I mainly use Clang on WSL, so I specify it in the command. Now let's build the source.<pre class=language-sh data-lang=sh style=color:#c0c5ce;background-color:#2b303b><code class=language-sh data-lang=sh><span style=color:#bf616a>$</span><span> cmake</span><span style=color:#bf616a> --build</span><span> build && </span><span style=color:#bf616a>cmake --install</span><span> build
</span></code></pre><p>This will build the code, produce a <code>.so</code> file, and install the library under <code>devblas_libs/devblas</code> in the source root.<p>To link a <code>C</code> file with the <code>.so</code> file, compile the file like this (from the repository root):<pre class=language-sh data-lang=sh style=color:#c0c5ce;background-color:#2b303b><code class=language-sh data-lang=sh><span style=color:#bf616a>$</span><span> clang test.c</span><span style=color:#bf616a> -o</span><span> test</span><span style=color:#bf616a> -Iinclude -Ldevblas_libs -ldevblas
</span></code></pre><p>To run the <code>test</code> binary, preload the shared object file and invoke the executable.<pre class=language-sh data-lang=sh style=color:#c0c5ce;background-color:#2b303b><code class=language-sh data-lang=sh><span style=color:#bf616a>$</span><span> LD_PRELOAD=devblas_libs/devblas/libdevblas.so ./test
</span></code></pre><p>To make the experimentation process easier, I've provided an example file called <code>bench_driver.c</code> in the top-level. It will automatically link with the produced <code>.so</code> file, so you won't have to go through the hassle of linking manually. To enable compilation of <code>bench_driver.c</code>, add <code>-DDEVBLAS_BUILD_BENCH=ON</code> to the CMake command, and it should produce a binary called <code>bench_driver</code> in the build dir.<pre class=language-sh data-lang=sh style=color:#c0c5ce;background-color:#2b303b><code class=language-sh data-lang=sh><span style=color:#bf616a>$</span><span> cmake</span><span style=color:#bf616a> -S</span><span>.</span><span style=color:#bf616a> -Bbuild -GNinja -DCMAKE_C_COMPILER</span><span>=clang \
</span><span style=color:#bf616a>  -DCMAKE_CXX_COMPILER</span><span>=clang++ \
</span><span style=color:#bf616a>  -DCMAKE_BUILD_TYPE</span><span>=Release \
</span><span style=color:#bf616a>  -DDEVBLAS_BUILD_BENCH</span><span>=ON
</span><span style=color:#bf616a>$</span><span> build/bench_driver
</span><span style=color:#bf616a>naive_gemm_ijk_driver:
</span><span>        </span><span style=color:#bf616a>Average</span><span> GFLOP/s: 0.601536
</span><span style=color:#bf616a>naive_gemm_ijk_driver:
</span><span>        </span><span style=color:#bf616a>Average</span><span> GFLOP/s: 0.611877
</span></code></pre><h3 id=the-benchmarking-harness>The Benchmarking Harness</h3><p>The benchmarking harness is a crucial feature of the library, because we will make extensive use of it to benchmark our kernel implementations as we progress with the series. Internal details are irrelevant to this post (we shall always use the C bindings, so it is much easier to just read the internal details on Github), so we will omit them here.<p>The benchmarking harness provides two benchmarking functions, called <code>bench_igemm(...)</code> for IGEMMs and <code>bench_sgemm(...)</code> for SGEMMs.<p>Let's look at the <code>bench_driver.c</code> file to see how they're used.<pre class=language-c data-lang=c style=color:#c0c5ce;background-color:#2b303b><code class=language-c data-lang=c><span style=color:#b48ead>#include </span><span>"</span><span style=color:#a3be8c>devblas/c_api/blas.h</span><span>"
</span><span style=color:#b48ead>#include </span><span>&lt;</span><span style=color:#a3be8c>assert.h</span><span>>
</span><span style=color:#b48ead>#include </span><span>&lt;</span><span style=color:#a3be8c>stdio.h</span><span>>
</span><span>
</span><span style=color:#b48ead>int </span><span style=color:#8fa1b3>main</span><span>(</span><span style=color:#b48ead>void</span><span>) {
</span><span>  </span><span style=color:#bf616a>bench_igemm</span><span>(naive_igemm_ijk, "</span><span style=color:#a3be8c>naive_gemm_ijk_driver</span><span>", </span><span style=color:#d08770>1</span><span>, </span><span style=color:#d08770>3</span><span>,
</span><span>              DEVBLAS_LAYOUT_ROW_MAJOR, </span><span style=color:#d08770>1024</span><span>, </span><span style=color:#d08770>1024</span><span>, </span><span style=color:#d08770>1024</span><span>, </span><span style=color:#d08770>1024</span><span>, </span><span style=color:#d08770>1024</span><span>, </span><span style=color:#d08770>1024</span><span>);
</span><span>  </span><span style=color:#bf616a>bench_sgemm</span><span>(naive_sgemm_ijk, "</span><span style=color:#a3be8c>naive_gemm_ijk_driver</span><span>", </span><span style=color:#d08770>1</span><span>, </span><span style=color:#d08770>3</span><span>,
</span><span>              DEVBLAS_LAYOUT_COLUMN_MAJOR, </span><span style=color:#d08770>1024</span><span>, </span><span style=color:#d08770>1024</span><span>, </span><span style=color:#d08770>1024</span><span>, </span><span style=color:#d08770>1024</span><span>, </span><span style=color:#d08770>1024</span><span>, </span><span style=color:#d08770>1024</span><span>);
</span><span>  </span><span style=color:#b48ead>return </span><span style=color:#d08770>0</span><span>;
</span><span>}
</span></code></pre><p>Both the functions follow a very similar signature, differing only in the data types of the matrices. We'll just talk about <code>bench_sgemm(...)</code> from now, and everything should apply to <code>bench_igemm(...)</code> as well.<p>The first argument is a function pointer, <code>naive_sgemm_ijk</code>. It points to our implementation of the naive SGEMM that we called <code>matmul()</code> in the previous post. Its signature is:<pre class=language-c data-lang=c style=color:#c0c5ce;background-color:#2b303b><code class=language-c data-lang=c><span style=color:#b48ead>void </span><span style=color:#8fa1b3>naive_sgemm_ijk</span><span>(</span><span style=color:#bf616a>devblas_layout_t</span><span>, </span><span style=color:#b48ead>const float </span><span>*, </span><span style=color:#b48ead>const float </span><span>*, </span><span style=color:#b48ead>float </span><span>*,
</span><span>                     </span><span style=color:#bf616a>int</span><span>, </span><span style=color:#bf616a>int</span><span>, </span><span style=color:#bf616a>int</span><span>, </span><span style=color:#bf616a>int</span><span>, </span><span style=color:#bf616a>int</span><span>, </span><span style=color:#bf616a>int</span><span>);
</span></code></pre><p>It takes a layout (we'll talk about that very soon), pointers to the input matrices, pointer to the output matrix, the integers <code>M</code>, <code>N</code>, <code>K</code>, (the matrix dimensions), and <code>lda</code>, <code>ldb</code>, <code>ldc</code> (the leading dimensions, which I'll get to very soon too).<p>The second argument to the benchmark function is the name of the benchmark that makes it easier to understand the logging. It defaults to <code>default_naive_sgemm</code> if the value is <code>NULL</code>. Third argument is the number of warmup iterations to run so that we are not timing cold runs, and following that is the number of iterations to actually run and measure. The rest of the arguments are just values that the <code>naive_sgemm_ijk</code> function will accept, so that the harness can run it with the correct arguments.<p>Let's write a very simple example "kernel" and plug that into the benchmark function.<pre class=language-c data-lang=c style=color:#c0c5ce;background-color:#2b303b><code class=language-c data-lang=c><span style=color:#b48ead>#include </span><span>"</span><span style=color:#a3be8c>devblas/c_api/blas.h</span><span>"
</span><span style=color:#b48ead>#include </span><span>&lt;</span><span style=color:#a3be8c>stdio.h</span><span>>
</span><span>
</span><span style=color:#b48ead>void </span><span style=color:#8fa1b3>my_experimental_kernel</span><span>(</span><span style=color:#bf616a>devblas_layout_t</span><span>, </span><span style=color:#b48ead>const float </span><span>*, </span><span style=color:#b48ead>const float </span><span>*, </span><span style=color:#b48ead>float </span><span>*,
</span><span>                            </span><span style=color:#bf616a>int</span><span>, </span><span style=color:#bf616a>int</span><span>, </span><span style=color:#bf616a>int</span><span>, </span><span style=color:#bf616a>int</span><span>, </span><span style=color:#bf616a>int</span><span>, </span><span style=color:#bf616a>int</span><span>) {
</span><span>  </span><span style=color:#96b5b4>printf</span><span>("</span><span style=color:#a3be8c>Hello, World!</span><span style=color:#96b5b4>\n</span><span>");
</span><span>}
</span><span>
</span><span style=color:#b48ead>int </span><span style=color:#8fa1b3>main</span><span>(</span><span style=color:#b48ead>void</span><span>) {
</span><span>  </span><span style=color:#bf616a>bench_sgemm</span><span>(my_experimental_kernel, "</span><span style=color:#a3be8c>my_experimental_kernel</span><span>", </span><span style=color:#d08770>0</span><span>, </span><span style=color:#d08770>10</span><span>,
</span><span>              DEVBLAS_LAYOUT_ROW_MAJOR, </span><span style=color:#d08770>0</span><span>, </span><span style=color:#d08770>0</span><span>, </span><span style=color:#d08770>0</span><span>, </span><span style=color:#d08770>0</span><span>, </span><span style=color:#d08770>0</span><span>, </span><span style=color:#d08770>0</span><span>);
</span><span>  </span><span style=color:#b48ead>return </span><span style=color:#d08770>0</span><span>;
</span><span>}
</span></code></pre><p>In this example, we are just printing "Hello, World!" in our kernel, and telling the benchmark function to not warmup and run this function 10 times. Matrix sizes and leading dimensions (what we called <code>lda</code>, <code>ldb</code> and <code>ldc</code>) are all <code>0</code> so that we don't allocate any matrices inside the benchmark function.<p>This outputs something like this:<pre style=color:#c0c5ce;background-color:#2b303b><code><span>Hello, World!
</span><span>Hello, World!
</span><span>Hello, World!
</span><span>Hello, World!
</span><span>Hello, World!
</span><span>Hello, World!
</span><span>Hello, World!
</span><span>Hello, World!
</span><span>Hello, World!
</span><span>Hello, World!
</span><span>my_experimental_kernel:
</span><span>        Average GFLOP/s: -nan
</span></code></pre><p>The function got called 10 times, as we expected, and gave <code>-nan</code> as the average GFLOP/s count. That's expected, we didn't give it anything to compute.<p>For a legitimate kernel function, it will produce a valid GFLOP/s value that should give a fair idea of what slows down a kernel and what speeds it up.<p>That is all we need to know about benchmarking for now. Let's move to...<h3 id=layout>Layout</h3><p>In general, no reasonable library will represent a matrix as a 2-D nested array. In general, matrices are stored as 1-D arrays, and we use the concept of strides to calculate which index in the 1-D array maps to the required index in 2-D.<p>Now, anyone familiar with C or C++ will think of a 2-D matrix as a collection of multiple row arrays. However, initial BLAS implementations and Fortran, which was (and still is) heavily used for scientific computing, represented 2-D matrices in a column-major order. So instead of traversing the rows first, you traverse the columns first.<p>In a setup that stores matrices as 1-D arrays, we can easily change our access pattern to switch between a row-major (as we have it in C, arrays of rows) or a column-major (as we have it in Fortran, array of columns) layout.<p>Let's consider the following matrix: $$ \begin{pmatrix} a & b \\ c & d \end{pmatrix} $$<p>In a row-major format, the stored 1-D array would look like this $$ \begin{bmatrix} a & b & c & d \end{bmatrix} $$<p>So when you access the next element, it is either the next one in this row, or the first element in the <em>next</em> row.<p>However, in a column-major layout, we would walk the matrix column first, something like this: $$ \begin{bmatrix} a & c & b & d \end{bmatrix} $$ so that <code>c</code> (just below <code>a</code>) becomes the element next to <code>a</code> in the 1-D array.<p>That is what layouts do. They just change the storage and access pattern of the 1-D array that represents the 2-D matrix.<h3 id=leading-dimensions>Leading dimensions</h3><p>Another thing that we kept for later was the concept of leading dimensions (referred to as <code>lda</code>, <code>ldb</code>, <code>ldc</code>) above.<p>Now, it is not always necessary that we will want to multiply the whole matrix in one go. There is a very high probability that you might need to multiply <strong>submatrices</strong>, and that is exactly what leading dimensions do.<p>Let's extend the matrix we wrote above to a larger <code>3x3</code> size $$ \begin{pmatrix} a & b & c \\ d & e & f \\ g & h & i \end{pmatrix} $$<p>Now let's say we have another matrix of the same size, but we don't want to multiply the whole matrix. Suppose we want to multiply the top left <code>2x2</code> submatrix. $$ S = \begin{pmatrix} a & b \\ d & e \end{pmatrix} $$<p>Assuming a row-major layout, we pass in the dimensions of the submatrix, <code>M=2</code>, <code>N=2</code>, <code>K=2</code> into the GEMM function. However, our matrices are <em>not</em> <code>2x2</code> in size, they are <code>3x3</code>. Therefore, to actually land on the first element of the next <em>logical</em> row, we pass in a leading dimension of <code>3</code> for both the input matrices.<p>This means that we'll access first <code>K</code> successive elements for each row for first matrix of size <code>MxK</code>, and the moment we cross <code>K</code>, we move from the end of this <em>logical</em> row to the start of the next one by skipping <code>(lda - K)</code> elements. Accessing the elements requires us to compute the stride, which means how many elements we need to jump to reach the first element of row $R+1$ from the first element of row $R$.<p>And leading dimensions are exactly that: the stride values used when operating on submatrices.<h3 id=closing-comments>Closing comments</h3><p>This was a text-heavy post, but it was necessary to introduce you to the architecture of the library, because I will be using it heavily in the upcoming posts.<p>I did not want to clutter subsequent posts (which will be theory- and visualization-heavy) with library implementation details, and it seemed better to introduce them before we start on that kind of stuff and you get lost in the clutter.<p>I'll introduce the memory hierarchy, cache behavior, and locality in the next post, and we'll modify our naive GEMM kernel and benchmark the modifications as we discuss the concepts, so that we can observe their effects.<p>The next post will be out in a while. Stay tuned!</section></article></main></div>